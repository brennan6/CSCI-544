{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "4bd340de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "b93fa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in data:\n",
    "tr_headers = [\"index\", \"word\", \"pos_tag\"]\n",
    "train_df = pd.read_csv(\"./data/train\", sep=\"\\t\", header=None)\n",
    "train_df.columns = tr_headers\n",
    "\n",
    "dev_df = pd.read_csv(\"./data/dev\", sep=\"\\t\", header=None)\n",
    "dev_df.columns = tr_headers\n",
    "\n",
    "test_headers = [\"index\", \"word\"]\n",
    "test_df = pd.read_csv(\"./data/test\", sep=\"\\t\", header=None)\n",
    "test_df.columns = test_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3639a65",
   "metadata": {},
   "source": [
    "### 1) Vocabulary Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "fe0ee1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>19</td>\n",
       "      <td>352.7</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>11</td>\n",
       "      <td>8.12</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>12</td>\n",
       "      <td>8.22</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911847</th>\n",
       "      <td>25</td>\n",
       "      <td>2.125</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911854</th>\n",
       "      <td>32</td>\n",
       "      <td>46.125</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911976</th>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912056</th>\n",
       "      <td>7</td>\n",
       "      <td>2,480</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912073</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6563 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index    word pos_tag\n",
       "16         17      29      CD\n",
       "356        11      28      CD\n",
       "1049       19   352.7      CD\n",
       "1143       11    8.12      CD\n",
       "1162       12    8.22      CD\n",
       "...       ...     ...     ...\n",
       "911847     25   2.125      CD\n",
       "911854     32  46.125      CD\n",
       "911976     26      32      CD\n",
       "912056      7   2,480      CD\n",
       "912073      5      20      CD\n",
       "\n",
       "[6563 rows x 3 columns]"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"].str.contains(\"2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "ce3de2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slight cleaning on num:\n",
    "train_df[\"word\"] = train_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)\n",
    "dev_df[\"word\"] = dev_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)\n",
    "test_df[\"word\"] = test_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "e2bdf2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each word:\n",
    "#word-type = word\n",
    "cnt_d = {}\n",
    "for row in train_df.iterrows():\n",
    "    if row[1][\"word\"] in cnt_d:\n",
    "        cnt_d[row[1][\"word\"]] += 1\n",
    "    else:\n",
    "        cnt_d[row[1][\"word\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "c28ba4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unknown key:\n",
    "threshold = 2 #No threshold = 1\n",
    "unknown_cnt = 0\n",
    "unknown_word_lst = []   #We want to keep track of unknown words but group together\n",
    "for k, v in cnt_d.items():\n",
    "    if v < threshold:\n",
    "        unknown_cnt += v\n",
    "        unknown_word_lst.append(k)\n",
    "    else:\n",
    "        continue\n",
    "cnt_d[\"< unk >\"] = unknown_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "f2b6a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the occurences in descending order:\n",
    "cnt_d_sorted = {k: v for k, v in sorted(cnt_d.items(), key=lambda item: -item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "da4a3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write the vocab to vocab.txt\n",
    "#punctuation and numbers also count as being part of vocabulary\n",
    "i = 0\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    f.write(\"< unk >\")\n",
    "    f.write(\"\\t\")\n",
    "    f.write(str(i))\n",
    "    f.write(\"\\t\")\n",
    "    f.write(str(cnt_d_sorted[\"< unk >\"]))\n",
    "    f.write(\"\\n\")\n",
    "    i+=1\n",
    "    for k, v in cnt_d_sorted.items():\n",
    "        if k == \"< unk >\":\n",
    "            continue\n",
    "        elif v >= threshold:\n",
    "            f.write(k)\n",
    "            f.write(\"\\t\")\n",
    "            f.write(str(i))\n",
    "            f.write(\"\\t\")\n",
    "            f.write(str(v))\n",
    "            f.write(\"\\n\")\n",
    "            i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "2aaf5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected threshold:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "d83f7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size of Vocab: 21436\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Size of Vocab:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "99b193ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total occurences of < unk >: 17019\n"
     ]
    }
   ],
   "source": [
    "print(\"Total occurences of < unk >:\", cnt_d_sorted[\"< unk >\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "23555452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the vocab file:\n",
    "vocab_d = {} #want just 0,word1... 90,word90 mapping\n",
    "vocab_file = open(\"vocab.txt\", \"r\").read().splitlines()\n",
    "\n",
    "\n",
    "for line in vocab_file:\n",
    "    line_split = line.split(\"\\n\")\n",
    "    for actual_line in line_split:\n",
    "        actual_line_split = actual_line.split(\"\\t\")\n",
    "        if len(actual_line_split) == 1:\n",
    "            break\n",
    "        vocab_d[int(actual_line_split[1])] = actual_line_split[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ef2f8",
   "metadata": {},
   "source": [
    "### 2. Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "76673531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;num&gt;</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word pos_tag\n",
       "0      1  Pierre     NNP\n",
       "1      2  Vinken     NNP\n",
       "2      3       ,       ,\n",
       "3      4   <num>      CD\n",
       "4      5   years     NNS"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "001b7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transition Prob. must create prob of all pos_tag transitions, contain in dictionary:\n",
    "pos_tag_d = {}\n",
    "all_pos_tags = train_df[\"pos_tag\"].values\n",
    "for i, pos_tag in enumerate(all_pos_tags):\n",
    "    if i == (len(all_pos_tags) - 1):\n",
    "        break\n",
    "    \n",
    "    next_tag = all_pos_tags[i+1]\n",
    "    if pos_tag in pos_tag_d:\n",
    "        if next_tag in pos_tag_d[pos_tag]:\n",
    "            pos_tag_d[pos_tag][next_tag] += 1\n",
    "        else:\n",
    "            pos_tag_d[pos_tag][next_tag] = 1\n",
    "            \n",
    "    else:\n",
    "        pos_tag_d[pos_tag] = {}\n",
    "        pos_tag_d[pos_tag][next_tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "d2bccaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need count of transition state individually:\n",
    "pos_total_counts_d = {}\n",
    "for k, v in pos_tag_d.items():\n",
    "    pos_total_counts_d[k] = 0\n",
    "    for k_inner, v_inner in v.items():\n",
    "        pos_total_counts_d[k] += v_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "a672e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transtion prob:\n",
    "transition_d = {}\n",
    "for k, v in pos_tag_d.items():\n",
    "    transition_d[k] = {}\n",
    "    for k_inner, v_inner in v.items():\n",
    "        transition_d[k][k_inner] = v_inner/pos_total_counts_d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "697361fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format transition d as wanted:\n",
    "transition_d_formatted = {}\n",
    "for k, v in transition_d.items():\n",
    "    for k_inner, v_inner in v.items():\n",
    "        key_str = str(k) + \", \" + str(k_inner)\n",
    "        transition_d_formatted[key_str] = transition_d[k][k_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "588ec52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Emission Prob - Must create prob of word given POS tag. Check if word is in Unknown Lst:\n",
    "#Takes ~3 min to run\n",
    "pos_to_word_d = {}\n",
    "all_pos_tags = train_df[\"pos_tag\"].values\n",
    "all_words = train_df[\"word\"].values\n",
    "for i, pos_tag in enumerate(all_pos_tags):\n",
    "    word = all_words[i]\n",
    "    if pos_tag in pos_to_word_d:\n",
    "        if word in unknown_word_lst:\n",
    "            if \"< unk >\" in pos_to_word_d[pos_tag]:\n",
    "                pos_to_word_d[pos_tag][\"< unk >\"] += 1\n",
    "            else:\n",
    "                pos_to_word_d[pos_tag][\"< unk >\"] = 1\n",
    "        else:\n",
    "            if word in pos_to_word_d[pos_tag]:\n",
    "                pos_to_word_d[pos_tag][word] += 1\n",
    "            else:\n",
    "                pos_to_word_d[pos_tag][word] = 1\n",
    "            \n",
    "    else:\n",
    "        pos_to_word_d[pos_tag] = {}\n",
    "        pos_to_word_d[pos_tag][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "3009920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create emission prob:\n",
    "emission_d = {}\n",
    "for k, v in pos_to_word_d.items():\n",
    "    emission_d[k] = {}\n",
    "    for k_inner, v_inner in v.items():\n",
    "        emission_d[k][k_inner] = v_inner/pos_total_counts_d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "043c2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format emission d as wanted:\n",
    "emission_d_formatted = {}\n",
    "for k, v in emission_d.items():\n",
    "    for k_inner, v_inner in v.items():\n",
    "        key_str = str(k) + \", \" + str(k_inner)\n",
    "        emission_d_formatted[key_str] = emission_d[k][k_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "4254461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate emission/transition:\n",
    "e_t_results_d = {}\n",
    "e_t_results_d[\"transition\"] = transition_d_formatted\n",
    "e_t_results_d[\"emission\"] = emission_d_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "10009b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Emission/Transition Prob to a file:\n",
    "with open('hmm.json', 'w') as f:\n",
    "    json.dump(e_t_results_d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "af495db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Transition Parameters: 1378\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Transition Parameters:\", len(transition_d_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "1ecbddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Emission Parameters: 28532\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Emission Parameters:\", len(emission_d_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "638714d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Emission/Transition json:\n",
    "hmm = open(\"hmm.json\", \"r\")\n",
    "e_t_model = json.load(hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371557f4",
   "metadata": {},
   "source": [
    "### 3. Greedy Decoding with HMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "91ea53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1* = arg max t(s1)e(x1|s1)\n",
    "# s2* = arg max t(s2|s1*)e(x2|s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "82dcf3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate best odds to be t(s1):\n",
    "most_likely_start_d = {}\n",
    "pos_tags_start = train_df[train_df[\"index\"] == 1][\"pos_tag\"]\n",
    "for pos_tag in pos_tags_start:\n",
    "    if pos_tag in most_likely_start_d:\n",
    "        most_likely_start_d[pos_tag] += 1\n",
    "    else:\n",
    "        most_likely_start_d[pos_tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "84bb9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_start_prob_d = {k:v/len(pos_tags_start) for k,v in most_likely_start_d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "168ff565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NNP': 0.19789104610393007,\n",
       " 'DT': 0.21911141347009264,\n",
       " 'IN': 0.1288398137003506,\n",
       " 'PRP': 0.06148935056779528,\n",
       " 'EX': 0.004238840337013972,\n",
       " '``': 0.07472918520069077,\n",
       " 'CD': 0.011225077188759224,\n",
       " 'RBR': 0.0020932544874143074,\n",
       " 'NNS': 0.041237113402061855,\n",
       " 'NN': 0.0411847820398765,\n",
       " 'JJ': 0.041708095661730074,\n",
       " 'JJR': 0.0017007692710241248,\n",
       " 'RB': 0.05604688890051808,\n",
       " 'WRB': 0.00609660369459417,\n",
       " 'CC': 0.05691035637657648,\n",
       " 'VBG': 0.012010047621539588,\n",
       " 'WDT': 0.0008111361138730441,\n",
       " 'VBN': 0.005834946883667382,\n",
       " '-LRB-': 0.003427704223140928,\n",
       " 'VB': 0.0030613846878434245,\n",
       " 'WP': 0.003113716050028782,\n",
       " 'PRP$': 0.007797372965618295,\n",
       " 'TO': 0.0035323669475116437,\n",
       " 'JJS': 0.00248573970380449,\n",
       " 'NNPS': 0.0020409231252289496,\n",
       " 'VBZ': 0.001517609503375373,\n",
       " 'VBD': 0.0007588047516876865,\n",
       " 'LS': 0.0009157988382437595,\n",
       " \"''\": 0.0003663195352975038,\n",
       " ':': 0.002799727876916636,\n",
       " 'VBP': 0.0003663195352975038,\n",
       " 'PDT': 0.0007326390705950076,\n",
       " 'UH': 0.0006279763462242922,\n",
       " 'MD': 0.0005494793029462557,\n",
       " '$': 0.0008634674760584018,\n",
       " 'RBS': 0.0005233136218535768,\n",
       " 'FW': 0.0001831597676487519,\n",
       " 'SYM': 0.0010989586058925114,\n",
       " '-RRB-': 2.6165681092678842e-05,\n",
       " 'WP$': 2.6165681092678842e-05,\n",
       " '#': 2.6165681092678842e-05}"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_start_prob_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "04f2a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_hmm(df):\n",
    "    \"\"\"Allows for a greedy implementation of HMM. Input - Dataframe that has words as column.\"\"\"\n",
    "    pred_lst = []\n",
    "    all_words = df[\"word\"].values\n",
    "    prev_pos = \"None\"\n",
    "    for i, word in enumerate(all_words):\n",
    "        best_prob = 0\n",
    "        best_pos = \"None\"\n",
    "        if (word in unknown_word_lst) or (word not in cnt_d_sorted):\n",
    "            word = \"< unk >\"\n",
    "        if i == 0:\n",
    "            for pos_tag in emission_d.keys():\n",
    "                if word in emission_d[pos_tag]: \n",
    "                    e_x1_s1 = emission_d[pos_tag][word]*most_likely_start_prob_d[pos_tag]\n",
    "                    if e_x1_s1 > best_prob:\n",
    "                        best_prob = e_x1_s1\n",
    "                        best_pos = pos_tag\n",
    "                else:\n",
    "                    continue\n",
    "            pred_lst.append(best_pos)\n",
    "            prev_pos = best_pos\n",
    "        else:\n",
    "            for pos_tag in emission_d.keys():\n",
    "                if word in emission_d[pos_tag]:\n",
    "                    e_x2_s2 = emission_d[pos_tag][word]\n",
    "                    if pos_tag in transition_d[prev_pos]:\n",
    "                        t_s2_s1 = transition_d[prev_pos][pos_tag]\n",
    "                    else:\n",
    "                        t_s2_s1 = 0\n",
    "                    prob_ = e_x2_s2*t_s2_s1\n",
    "                    if prob_ > best_prob:\n",
    "                        best_prob = prob_\n",
    "                        best_pos = pos_tag\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if best_pos == \"None\": #Edge case where word and POS DO NOT Allign\n",
    "                for pos_tag in emission_d.keys():\n",
    "                    if word in emission_d[pos_tag]:\n",
    "                        e_x2_s2 = emission_d[pos_tag][word]\n",
    "                        if e_x2_s2 > best_prob:\n",
    "                            best_prob = e_x2_s2\n",
    "                            best_pos = pos_tag\n",
    "            pred_lst.append(best_pos)\n",
    "            prev_pos = best_pos\n",
    "            \n",
    "    return pred_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "a1dec520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data:\n",
    "train_pred_lst = greedy_hmm(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "4dd6239a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507014071999079"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_acc = sum(np.array(train_pred_lst) == train_df[\"pos_tag\"].values)/len(np.array(train_pred_lst))\n",
    "training_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "597114fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Dev Data:\n",
    "dev_pred_lst = greedy_hmm(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "704562ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9377618238115476"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_acc = sum(np.array(dev_pred_lst) == dev_df[\"pos_tag\"].values)/len(np.array(dev_pred_lst))\n",
    "dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "cc0619de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Data:\n",
    "test_pred_lst = greedy_hmm(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "2e524b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output of Test Data:\n",
    "with open(\"greedy.out\", \"w\") as g:\n",
    "    test_idx = test_df[\"index\"].values\n",
    "    test_word = test_df[\"word\"].values\n",
    "    for i, pred in enumerate(test_pred_lst):\n",
    "        g.write(str(test_idx[i]))\n",
    "        g.write(\"\\t\")\n",
    "        g.write(str(test_word[i]))\n",
    "        g.write(\"\\t\")\n",
    "        g.write(str(pred))\n",
    "        g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442512da",
   "metadata": {},
   "source": [
    "### 4. Viterbi Decoding With HMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "28c785f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_hmm(df):\n",
    "    \"\"\"Allows for a viterbi decoding implementation of HMM. Input - Dataframe that has words as column.\"\"\"\n",
    "    all_words = df[\"word\"].values\n",
    "    states = [k for k in emission_d.keys()]\n",
    "    V = []\n",
    "    for i, word in enumerate(all_words):\n",
    "        V.append({})\n",
    "        current_map = {}\n",
    "        if (word in unknown_word_lst) or (word not in cnt_d_sorted):\n",
    "            word = \"< unk >\"\n",
    "        if i == 0:\n",
    "            for pos_tag in states:\n",
    "                if word in emission_d[pos_tag]: \n",
    "                    e_x1_s1 = np.log(emission_d[pos_tag][word]) + np.log(most_likely_start_prob_d[pos_tag])\n",
    "                    current_map[pos_tag] = {\"prob\": e_x1_s1, \"prev_state\": None}\n",
    "                else:\n",
    "                    current_map[pos_tag] = {\"prob\": -50, \"prev_state\": None}\n",
    "            V[i] = current_map\n",
    "        else:\n",
    "            for pos_tag in states:\n",
    "                if pos_tag in transition_d[states[0]]:\n",
    "                    best_prob = V[i-1][states[0]][\"prob\"] + np.log(transition_d[states[0]][pos_tag])\n",
    "                else:\n",
    "                    best_prob = -1000000\n",
    "                past_st = states[0]\n",
    "                for prev_tag in states[1:]:\n",
    "                    if pos_tag in transition_d[prev_tag]:\n",
    "                        t_s2_s1 = np.log(transition_d[prev_tag][pos_tag])\n",
    "                    else:\n",
    "                        t_s2_s1 = -100\n",
    "                    tr_cost = V[i-1][prev_tag][\"prob\"] + t_s2_s1 #log or -100 penalty\n",
    "                    if tr_cost > best_prob:\n",
    "                        best_prob = tr_cost\n",
    "                        past_st = prev_tag\n",
    "                \n",
    "                if word in emission_d[pos_tag]:\n",
    "                    e_x1_s1 = np.log(emission_d[pos_tag][word])\n",
    "                else:\n",
    "                    e_x1_s1 = -100\n",
    "                best_prob = best_prob + e_x1_s1  #log or -100 penalty\n",
    "                V[i][pos_tag] = {\"prob\": best_prob, \"prev_state\": past_st}\n",
    "                \n",
    "    pred_lst = []\n",
    "    final_state = \".\" #init a guess of . ending\n",
    "    best_prob = -np.inf #init a guess of best prob\n",
    "    \n",
    "    #Figure out what the best final state is:\n",
    "    for st, d_ in V[len(all_words)-1].items():\n",
    "        if d_[\"prob\"] > best_prob:\n",
    "            final_state = st\n",
    "            best_prob = d_[\"prob\"]\n",
    "            \n",
    "    #Follow path from end to beginning      \n",
    "    for i in range(len(all_words)-2, -1, -1):\n",
    "        pred_lst.append(V[i+1][final_state][\"prev_state\"])\n",
    "        final_state = V[i+1][final_state][\"prev_state\"]\n",
    "        \n",
    "    return np.flip(np.array(pred_lst),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "e2129944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Dev Data:\n",
    "dev_pred_lst = viterbi_hmm(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "2f3d160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9505187186473093"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_acc = sum(1 for x,y in zip(dev_pred_lst, dev_df[\"pos_tag\"].values) if x == y)/len(dev_pred_lst)\n",
    "dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "05dcd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Data:\n",
    "test_pred_lst = viterbi_hmm(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "935078b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output of Test Data:\n",
    "with open(\"viterbi.out\", \"w\") as v:\n",
    "    test_idx = test_df[\"index\"].values\n",
    "    test_word = test_df[\"word\"].values\n",
    "    for i, pred in enumerate(test_pred_lst):\n",
    "        v.write(str(test_idx[i]))\n",
    "        v.write(\"\\t\")\n",
    "        v.write(str(test_word[i]))\n",
    "        v.write(\"\\t\")\n",
    "        v.write(str(pred))\n",
    "        v.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421e52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
