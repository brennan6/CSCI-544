{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f7ae0814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import sklearn\n",
    "import warnings\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ce2fdcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in data:\n",
    "tr_headers = [\"index\", \"word\", \"ner_tag\"]\n",
    "train_df = pd.read_csv(\"./data/train\", sep=' ', header=None, quoting=3)\n",
    "train_df.columns = tr_headers\n",
    "\n",
    "dev_df = pd.read_csv(\"./data/dev\", sep=' ', header=None, quoting=3)\n",
    "dev_df.columns = tr_headers\n",
    "\n",
    "test_headers = [\"index\", \"word\"]\n",
    "test_df = pd.read_csv(\"./data/test\", sep=' ', header=None, engine='python', error_bad_lines=False, quoting=3)\n",
    "test_df.columns = test_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1591f02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>28</td>\n",
       "      <td>advice</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>29</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30</td>\n",
       "      <td>clearer</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>31</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>We</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     word ner_tag\n",
       "70     28   advice       O\n",
       "71     29      was       O\n",
       "72     30  clearer       O\n",
       "73     31        .       O\n",
       "74      1        \"       O\n",
       "75      2       We       O"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[70:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9b543365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1996-08-22</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>European</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        word ner_tag\n",
       "0       1          EU   B-ORG\n",
       "1       2     rejects       O\n",
       "2       3      German  B-MISC\n",
       "3       4        call       O\n",
       "4       5          to       O\n",
       "..    ...         ...     ...\n",
       "10      2   Blackburn   I-PER\n",
       "11      1    BRUSSELS   B-LOC\n",
       "12      2  1996-08-22       O\n",
       "13      1         The       O\n",
       "14      2    European   B-ORG\n",
       "\n",
       "[15 rows x 3 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d0a0d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slight cleaning on num:\n",
    "train_df[\"word\"] = train_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)\n",
    "dev_df[\"word\"] = dev_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)\n",
    "test_df[\"word\"] = test_df[\"word\"].str.replace(r'^\\d+|.\\d+$', \"<num>\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "cbcc2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each word:\n",
    "#word-type = word\n",
    "cnt_d = {}\n",
    "for row in train_df.iterrows():\n",
    "    if row[1][\"word\"] in cnt_d:\n",
    "        cnt_d[row[1][\"word\"]] += 1\n",
    "    else:\n",
    "        cnt_d[row[1][\"word\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e28b4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2 #No threshold = 1\n",
    "#unknown_cnt = 0\n",
    "unknown_word_lst = []   #We want to keep track of unknown words but group together\n",
    "for k, v in cnt_d.items():\n",
    "    if v < threshold:\n",
    "        #unknown_cnt += v\n",
    "        unknown_word_lst.append(k)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fe497fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk_train(word):\n",
    "    if word in unknown_word_lst:\n",
    "        return \"<unk>\"\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "cac8b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unk_dev(word):\n",
    "    if word in unknown_word_lst:\n",
    "        return \"<unk>\"\n",
    "    elif word not in train_words:\n",
    "        return \"<unk>\"\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f98394fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace with <unk> Train:\n",
    "train_df[\"word\"] = train_df[\"word\"].apply(replace_unk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "454d5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"word\"] = train_df[\"word\"].astype(str)\n",
    "train_vocab_size = len(np.unique(train_df[\"word\"]))\n",
    "train_words = np.unique(train_df[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2a2bb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace with <unk> Dev:\n",
    "dev_df[\"word\"] = dev_df[\"word\"].apply(replace_unk_dev)\n",
    "dev_df[\"word\"] = dev_df[\"word\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "87b69c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>OVER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51574</th>\n",
       "      <td>2</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51575</th>\n",
       "      <td>3</td>\n",
       "      <td>Newsroom</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;num&gt;-2&lt;num&gt;</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51577</th>\n",
       "      <td>1</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51578 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index          word ner_tag\n",
       "0          1       CRICKET       O\n",
       "1          2             -       O\n",
       "2          3         <unk>   B-ORG\n",
       "3          4          TAKE       O\n",
       "4          5          OVER       O\n",
       "...      ...           ...     ...\n",
       "51573      1            --       O\n",
       "51574      2         Dhaka   B-ORG\n",
       "51575      3      Newsroom   I-ORG\n",
       "51576      4  <num>-2<num>       O\n",
       "51577      1    -DOCSTART-       O\n",
       "\n",
       "[51578 rows x 3 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "81ed641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the data by sentences TRAIN:\n",
    "def format_data(df):\n",
    "    train_formatted = []\n",
    "    #init beginning:\n",
    "    first_word = df.iloc[0]\n",
    "    sentence_x = [first_word[\"word\"]]\n",
    "    sentence_y = [first_word[\"ner_tag\"]]\n",
    "    \n",
    "    for row in df.iloc[1:].iterrows():\n",
    "        #print(row)\n",
    "        if row[1][\"index\"] == 1:\n",
    "            #print(row[1][\"word\"])\n",
    "            train_formatted.append([sentence_x, sentence_y])\n",
    "\n",
    "            sentence_x, sentence_y = [], []\n",
    "            sentence_x.append(row[1][\"word\"])\n",
    "            sentence_y.append(row[1][\"ner_tag\"])\n",
    "            if row[0] == (df.shape[0]-1):\n",
    "                train_formatted.append([sentence_x, sentence_y])\n",
    "        else:\n",
    "            sentence_x.append(row[1][\"word\"])\n",
    "            sentence_y.append(row[1][\"ner_tag\"])\n",
    "    return train_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "c35e68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the data by sentences TEST:\n",
    "def format_data_test(df):\n",
    "    test_formatted = []\n",
    "    #init beginning:\n",
    "    first_word = df.iloc[0]\n",
    "    sentence_x = [first_word[\"word_formatted\"]]\n",
    "    \n",
    "    for row in df.iloc[1:].iterrows():\n",
    "        if row[1][\"index\"] == 1:\n",
    "            test_formatted.append(sentence_x)\n",
    "\n",
    "            sentence_x = []\n",
    "            sentence_x.append(row[1][\"word_formatted\"])\n",
    "            if row[0] == (df.shape[0]-1):\n",
    "                train_formatted.append([sentence_x, sentence_y])\n",
    "        else:\n",
    "            sentence_x.append(row[1][\"word_formatted\"])\n",
    "    \n",
    "    return test_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "5ef3bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_formatted = format_data(train_df)\n",
    "dev_formatted = format_data(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "6fc6ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " 'WED': 1,\n",
       " 'Piotti': 2,\n",
       " 'Obilic': 3,\n",
       " 'Leander': 4,\n",
       " 'Feldhoff': 5,\n",
       " '+1<num>': 6,\n",
       " 'researchers': 7,\n",
       " 'alliance': 8,\n",
       " '<num>-0-14<num>': 9,\n",
       " 'nomination': 10,\n",
       " 'traffic': 11,\n",
       " 'companies': 12,\n",
       " 'soldier': 13,\n",
       " 'remain': 14,\n",
       " 'monitoring': 15,\n",
       " 'bike': 16,\n",
       " 'SHEFFIELD': 17,\n",
       " 'Drobnjak': 18,\n",
       " 'brains': 19,\n",
       " 'Parliament': 20,\n",
       " 'Chemical': 21,\n",
       " 'tracks': 22,\n",
       " 'Hlasek': 23,\n",
       " 'safety': 24,\n",
       " 'population': 25,\n",
       " 'Ryutaro': 26,\n",
       " 'Berasategui': 27,\n",
       " 'Federal': 28,\n",
       " 'Estates': 29,\n",
       " 'Granic': 30,\n",
       " 'examined': 31,\n",
       " 'Hintsa': 32,\n",
       " 'separatist': 33,\n",
       " 'Borussia': 34,\n",
       " 'understand': 35,\n",
       " 'Glyn': 36,\n",
       " 'regulation': 37,\n",
       " 'COLOMBO': 38,\n",
       " 'idea': 39,\n",
       " 'recovered': 40,\n",
       " 'registering': 41,\n",
       " 'flooding': 42,\n",
       " 'Srinath': 43,\n",
       " 'did': 44,\n",
       " 'Andy': 45,\n",
       " 'Rwanda': 46,\n",
       " 'brokers': 47,\n",
       " 'guns': 48,\n",
       " 'sold': 49,\n",
       " 'conviction': 50,\n",
       " 'Witschge': 51,\n",
       " 'semifinal': 52,\n",
       " 'Dean': 53,\n",
       " 'Wednesday': 54,\n",
       " 'holes': 55,\n",
       " 'Sint': 56,\n",
       " 'following': 57,\n",
       " 'sex': 58,\n",
       " 'Food': 59,\n",
       " 'REASONS': 60,\n",
       " 'Gloucestershire': 61,\n",
       " 'minutes': 62,\n",
       " 'socialists': 63,\n",
       " 'ATHLETICS': 64,\n",
       " 'planted': 65,\n",
       " 'corporations': 66,\n",
       " 'batter': 67,\n",
       " 'fun': 68,\n",
       " 'ventilation': 69,\n",
       " 'Experts': 70,\n",
       " 'vote': 71,\n",
       " 'prompt': 72,\n",
       " 'launching': 73,\n",
       " 'Internet': 74,\n",
       " 'trln': 75,\n",
       " 'BAYERISCHE': 76,\n",
       " 'Allan': 77,\n",
       " 'triggered': 78,\n",
       " 'Sudanese': 79,\n",
       " 'owners': 80,\n",
       " 'Cuba': 81,\n",
       " 'arc': 82,\n",
       " 'Impala': 83,\n",
       " 'KSE': 84,\n",
       " 'Tiger': 85,\n",
       " 'Boje': 86,\n",
       " 'proposes': 87,\n",
       " 'Zemin': 88,\n",
       " 'Klimis': 89,\n",
       " 'why': 90,\n",
       " 'sprinter': 91,\n",
       " 'Jennifer': 92,\n",
       " 'competitive': 93,\n",
       " 'utility': 94,\n",
       " 'Fitzroy': 95,\n",
       " 'homer': 96,\n",
       " 'shoes': 97,\n",
       " 'Magdalena': 98,\n",
       " 'murders': 99,\n",
       " 'Bahamas': 100,\n",
       " 'dozen': 101,\n",
       " 'JAKARTA': 102,\n",
       " 'At': 103,\n",
       " 'Ryan': 104,\n",
       " 'Ruben': 105,\n",
       " 'soccer': 106,\n",
       " 'Takeda': 107,\n",
       " 'medals': 108,\n",
       " 'approach': 109,\n",
       " 'Charlton': 110,\n",
       " 'quality': 111,\n",
       " 'handle': 112,\n",
       " 'Lambrecks': 113,\n",
       " 'Eyles': 114,\n",
       " 'calf': 115,\n",
       " 'BRATISLAVA': 116,\n",
       " 'happy': 117,\n",
       " 'silence': 118,\n",
       " 'turning': 119,\n",
       " 'character': 120,\n",
       " 'Five': 121,\n",
       " 'ADVANCE': 122,\n",
       " 'migrants': 123,\n",
       " 'IRISH': 124,\n",
       " 'mobile': 125,\n",
       " 'client': 126,\n",
       " 'Kent': 127,\n",
       " 'Bunds': 128,\n",
       " 'They': 129,\n",
       " \"'re\": 130,\n",
       " 'Close': 131,\n",
       " 'burden': 132,\n",
       " 'revolt': 133,\n",
       " 'Woosnam': 134,\n",
       " 'Relations': 135,\n",
       " 'UEFA': 136,\n",
       " 'JOURNAL': 137,\n",
       " 'interferon': 138,\n",
       " 'Bids': 139,\n",
       " 'titles': 140,\n",
       " 'dropping': 141,\n",
       " 'modest': 142,\n",
       " 'erupted': 143,\n",
       " 'SINGAPORE': 144,\n",
       " 'half': 145,\n",
       " 'holding': 146,\n",
       " 'golf': 147,\n",
       " 'Arab': 148,\n",
       " 'opportunities': 149,\n",
       " 'Norwich': 150,\n",
       " 'Puglisi': 151,\n",
       " 'temporary': 152,\n",
       " 'Ben': 153,\n",
       " 'logged': 154,\n",
       " 'fiasco': 155,\n",
       " 'Radstrom': 156,\n",
       " 'Zhilan': 157,\n",
       " 'Azad': 158,\n",
       " 'Jonathon': 159,\n",
       " '<num>:05<num>': 160,\n",
       " 'St.': 161,\n",
       " 'Kassala': 162,\n",
       " 'resulting': 163,\n",
       " 'Lewis': 164,\n",
       " 'call': 165,\n",
       " 'noted': 166,\n",
       " 'Domingo': 167,\n",
       " 'date': 168,\n",
       " 'layoffs': 169,\n",
       " 'run-up': 170,\n",
       " 'volcano': 171,\n",
       " 'Ajax': 172,\n",
       " '[': 173,\n",
       " 'unit': 174,\n",
       " 'Onyali': 175,\n",
       " 'substitute': 176,\n",
       " 'Mount': 177,\n",
       " 'injury': 178,\n",
       " 'Lech': 179,\n",
       " 'month-end': 180,\n",
       " 'journey': 181,\n",
       " 'running': 182,\n",
       " 'owns': 183,\n",
       " 'situation': 184,\n",
       " 'arrive': 185,\n",
       " 'division': 186,\n",
       " 'stopping': 187,\n",
       " 'Valentin': 188,\n",
       " '<num>mth': 189,\n",
       " 'realised': 190,\n",
       " 'stationery': 191,\n",
       " 'volatility': 192,\n",
       " 'Services': 193,\n",
       " 'Bugno': 194,\n",
       " 'Greece': 195,\n",
       " 'Rameswaram': 196,\n",
       " 'Rangoon': 197,\n",
       " 'introduce': 198,\n",
       " 'hang': 199,\n",
       " 'pre-war': 200,\n",
       " 'various': 201,\n",
       " 'Ayr': 202,\n",
       " 'underwent': 203,\n",
       " 'ZURICH': 204,\n",
       " 'sites': 205,\n",
       " 'debate': 206,\n",
       " 'expenses': 207,\n",
       " 'Perhaps': 208,\n",
       " 'Alexandre': 209,\n",
       " 'banks': 210,\n",
       " 'imminent': 211,\n",
       " 'Forwards': 212,\n",
       " 'throne': 213,\n",
       " 'secrets': 214,\n",
       " 'nan': 215,\n",
       " 'Shakhtar': 216,\n",
       " 'Hendrika': 217,\n",
       " 'Colorado': 218,\n",
       " 'MONTREAL': 219,\n",
       " 'sleep': 220,\n",
       " 'Kremin': 221,\n",
       " 'thermal': 222,\n",
       " 'pitcher': 223,\n",
       " 'drachmas': 224,\n",
       " 'explosives': 225,\n",
       " 'muscular': 226,\n",
       " 'duty': 227,\n",
       " 'filming': 228,\n",
       " 'Ottoz': 229,\n",
       " 'surgery': 230,\n",
       " 'Padres': 231,\n",
       " 'element': 232,\n",
       " 'refuelled': 233,\n",
       " 'Chaminda': 234,\n",
       " 'SRI': 235,\n",
       " 'silver': 236,\n",
       " 'asking': 237,\n",
       " 'reformist': 238,\n",
       " 'common': 239,\n",
       " 'heard': 240,\n",
       " 'thinks': 241,\n",
       " 'range': 242,\n",
       " 'Toyota': 243,\n",
       " 'Gastel': 244,\n",
       " 'SOFIA': 245,\n",
       " 'lot': 246,\n",
       " 'troubled': 247,\n",
       " 'Dionne': 248,\n",
       " 'Gruppen': 249,\n",
       " 'thanks': 250,\n",
       " 'Walton': 251,\n",
       " 'Welspun': 252,\n",
       " 'enable': 253,\n",
       " 'towards': 254,\n",
       " 'MON': 255,\n",
       " 'MONEY': 256,\n",
       " 'exactly': 257,\n",
       " 'SPD': 258,\n",
       " 'Rostselmash': 259,\n",
       " 'vowed': 260,\n",
       " 'resumed': 261,\n",
       " 'Barros': 262,\n",
       " 'Varteks': 263,\n",
       " 'Ocean': 264,\n",
       " 'chaos': 265,\n",
       " 'agricultural': 266,\n",
       " 'all': 267,\n",
       " 'Universe': 268,\n",
       " 'monetary': 269,\n",
       " 'worst': 270,\n",
       " 'family': 271,\n",
       " 'BORROWER': 272,\n",
       " 'lounge': 273,\n",
       " 'equivalent': 274,\n",
       " 'main': 275,\n",
       " 'Baath': 276,\n",
       " 'Christie': 277,\n",
       " 'ZDF': 278,\n",
       " 'faded': 279,\n",
       " 'threatening': 280,\n",
       " 'Maruyama': 281,\n",
       " 'freight-tonne': 282,\n",
       " 'create': 283,\n",
       " 'Citterio': 284,\n",
       " 'Neither': 285,\n",
       " 'Teresa': 286,\n",
       " 'TEST': 287,\n",
       " 'Online': 288,\n",
       " 'FIRST': 289,\n",
       " 'confessed': 290,\n",
       " 'Watford': 291,\n",
       " 'publishing': 292,\n",
       " 'Aaron': 293,\n",
       " 'wet': 294,\n",
       " 'projects': 295,\n",
       " 'older': 296,\n",
       " 'Gluten': 297,\n",
       " 'spokesman': 298,\n",
       " 'Reeve': 299,\n",
       " 'searches': 300,\n",
       " 'East': 301,\n",
       " 'Grozny': 302,\n",
       " 'scoreless': 303,\n",
       " '<num>,750-12<num>': 304,\n",
       " 'employer': 305,\n",
       " 'et': 306,\n",
       " 'points': 307,\n",
       " 'murdering': 308,\n",
       " 'include': 309,\n",
       " 'Corey': 310,\n",
       " 'NATO': 311,\n",
       " 'Jewish': 312,\n",
       " 'Bossi': 313,\n",
       " 'suburb': 314,\n",
       " 'Survey': 315,\n",
       " 'Special': 316,\n",
       " 'Beaver': 317,\n",
       " 'rebellion': 318,\n",
       " 'snapped': 319,\n",
       " 'violation': 320,\n",
       " 'bone': 321,\n",
       " 'fee': 322,\n",
       " 'fought': 323,\n",
       " 'Kigali': 324,\n",
       " 'indication': 325,\n",
       " 'Euromark': 326,\n",
       " 'former': 327,\n",
       " 'appear': 328,\n",
       " 'headed': 329,\n",
       " '<num>.25-1<num>': 330,\n",
       " 'spokeswoman': 331,\n",
       " 'feel': 332,\n",
       " 'Forget': 333,\n",
       " 'Crookes': 334,\n",
       " 'guilty': 335,\n",
       " 'hardest': 336,\n",
       " 'Amica': 337,\n",
       " 'Shiraz': 338,\n",
       " 'celebrated': 339,\n",
       " 'NASDAQ': 340,\n",
       " 'Rolf': 341,\n",
       " 'free': 342,\n",
       " 'candidate': 343,\n",
       " 'Rican': 344,\n",
       " 'discount': 345,\n",
       " 'Arthur': 346,\n",
       " 'brawl': 347,\n",
       " 'Headingley': 348,\n",
       " 'Enzo': 349,\n",
       " 'surgeon': 350,\n",
       " 'Lyon': 351,\n",
       " 'Cannes': 352,\n",
       " 'Nottinghamshire': 353,\n",
       " 'complete': 354,\n",
       " 'Overall': 355,\n",
       " 'Boer': 356,\n",
       " 'soil': 357,\n",
       " 'Ponting': 358,\n",
       " 'equities': 359,\n",
       " 'Vladimir': 360,\n",
       " 'LAW': 361,\n",
       " 'Olsztyn': 362,\n",
       " 'Partizan': 363,\n",
       " 'estimates': 364,\n",
       " 'Khadga': 365,\n",
       " 'moving': 366,\n",
       " 'finds': 367,\n",
       " 'weathered': 368,\n",
       " 'Strikers': 369,\n",
       " 'feeling': 370,\n",
       " 'fail': 371,\n",
       " 'Penrith': 372,\n",
       " '<num>:12<num>': 373,\n",
       " 'age': 374,\n",
       " 'sexually': 375,\n",
       " 'Slavia': 376,\n",
       " 'Bruguera': 377,\n",
       " 'Conchita': 378,\n",
       " 'Shah': 379,\n",
       " 'Wyborcza': 380,\n",
       " 'Larry': 381,\n",
       " 'showed': 382,\n",
       " 'together': 383,\n",
       " 'holds': 384,\n",
       " 'watching': 385,\n",
       " 'appealed': 386,\n",
       " 'friends': 387,\n",
       " 'Bevan': 388,\n",
       " 'Notts': 389,\n",
       " 'tactics': 390,\n",
       " 'dead': 391,\n",
       " 'Bordeaux': 392,\n",
       " 'detailed': 393,\n",
       " 'Shehu': 394,\n",
       " 'Egypt': 395,\n",
       " 'reduced': 396,\n",
       " 'Nicky': 397,\n",
       " 'baht': 398,\n",
       " 'persons': 399,\n",
       " 'Kroslak': 400,\n",
       " 'ingot': 401,\n",
       " 'Filip': 402,\n",
       " 'ballot': 403,\n",
       " 'mountainous': 404,\n",
       " 'neighbouring': 405,\n",
       " 'Ed': 406,\n",
       " 'AIRES': 407,\n",
       " 'Dhaka': 408,\n",
       " 'Court': 409,\n",
       " 'WOMEN': 410,\n",
       " 'Burnley': 411,\n",
       " 'REOFFER': 412,\n",
       " 'concessions': 413,\n",
       " 'Simian': 414,\n",
       " 'investigators': 415,\n",
       " 'cause': 416,\n",
       " 'lowers': 417,\n",
       " 'prospects': 418,\n",
       " 'Karl': 419,\n",
       " 'storming': 420,\n",
       " 'Banking': 421,\n",
       " 'Betaseron': 422,\n",
       " 'admitted': 423,\n",
       " 'Yr': 424,\n",
       " 'inquiry': 425,\n",
       " 'Jacques': 426,\n",
       " 'Rimavska': 427,\n",
       " 'fifth-seeded': 428,\n",
       " 'crowd': 429,\n",
       " 'covered': 430,\n",
       " 'Cross': 431,\n",
       " 'Dominion': 432,\n",
       " 'Damm': 433,\n",
       " 'attempt': 434,\n",
       " 'payment': 435,\n",
       " 'Manuel': 436,\n",
       " 'visible': 437,\n",
       " 'School': 438,\n",
       " 'interest': 439,\n",
       " 'high-speed': 440,\n",
       " 'ours': 441,\n",
       " 'least': 442,\n",
       " 'Weibring': 443,\n",
       " 'Grasshopper': 444,\n",
       " 'storm': 445,\n",
       " 'COUNCIL': 446,\n",
       " 'Liege': 447,\n",
       " 'CEO': 448,\n",
       " 'reached': 449,\n",
       " 'stabbed': 450,\n",
       " 'Diniz': 451,\n",
       " 'ordering': 452,\n",
       " 'disappointed': 453,\n",
       " 'Verstappen': 454,\n",
       " 'Newsdesk': 455,\n",
       " 'Lance': 456,\n",
       " 'reserve': 457,\n",
       " 'nominee': 458,\n",
       " 'Dominic': 459,\n",
       " 'occurred': 460,\n",
       " 'Cathy': 461,\n",
       " 'Redgrave': 462,\n",
       " 'apparently': 463,\n",
       " 'PRECIOUS': 464,\n",
       " 'stunning': 465,\n",
       " 'Russian-Chechen': 466,\n",
       " 'prefix': 467,\n",
       " 'Fitzpatrick': 468,\n",
       " 'CDU': 469,\n",
       " 'fishermen': 470,\n",
       " 'broken': 471,\n",
       " 'Boldon': 472,\n",
       " 'down': 473,\n",
       " 'Krylya': 474,\n",
       " 'Roger': 475,\n",
       " 'empty': 476,\n",
       " 'dyed': 477,\n",
       " 'Hans': 478,\n",
       " 'veteran': 479,\n",
       " 'Dukla': 480,\n",
       " 'Sidot': 481,\n",
       " 'SIX': 482,\n",
       " 'Heeswijk': 483,\n",
       " 'logging': 484,\n",
       " 'Mills': 485,\n",
       " 'Hansma': 486,\n",
       " 'Krpaco': 487,\n",
       " 'fully': 488,\n",
       " 'signature': 489,\n",
       " 'man': 490,\n",
       " 'unhurt': 491,\n",
       " 'Share': 492,\n",
       " 'vouch': 493,\n",
       " 'batters': 494,\n",
       " 'Evert': 495,\n",
       " 'jars': 496,\n",
       " 'DDF': 497,\n",
       " 'Heidrun': 498,\n",
       " 'Akam': 499,\n",
       " 'customs': 500,\n",
       " 'enquiries': 501,\n",
       " 'Trafford': 502,\n",
       " 'protects': 503,\n",
       " 'Op': 504,\n",
       " 'interests': 505,\n",
       " 'Expectations': 506,\n",
       " 'denial': 507,\n",
       " 'stayed': 508,\n",
       " 'Norris': 509,\n",
       " 'Neagle': 510,\n",
       " 'batting': 511,\n",
       " 'Valle': 512,\n",
       " 'some': 513,\n",
       " 'firm': 514,\n",
       " 'Another': 515,\n",
       " 'invading': 516,\n",
       " 'PAULO': 517,\n",
       " 'aluminium': 518,\n",
       " 'Heinz-Harald': 519,\n",
       " 'religious': 520,\n",
       " 'badminton': 521,\n",
       " 'deals': 522,\n",
       " 'And': 523,\n",
       " 'Kubo': 524,\n",
       " 'Hawthorn': 525,\n",
       " 'steal': 526,\n",
       " 'read': 527,\n",
       " 'Brighton': 528,\n",
       " 'abusing': 529,\n",
       " 'training': 530,\n",
       " 'Eco-Challenge': 531,\n",
       " 'injuries': 532,\n",
       " 'reverts': 533,\n",
       " 'beyond': 534,\n",
       " 'renew': 535,\n",
       " 'Mike': 536,\n",
       " 'Agreement': 537,\n",
       " 'Showers': 538,\n",
       " 'often': 539,\n",
       " 'software': 540,\n",
       " 'Moeller': 541,\n",
       " 'Griqualand': 542,\n",
       " 'Martina': 543,\n",
       " 'Uralmash': 544,\n",
       " 'Bangladeshi': 545,\n",
       " 'America': 546,\n",
       " 'Penrose': 547,\n",
       " 'kicked': 548,\n",
       " 'Sandrine': 549,\n",
       " 'submit': 550,\n",
       " 'scale': 551,\n",
       " 'choose': 552,\n",
       " 'magazine': 553,\n",
       " 'document': 554,\n",
       " 'prompted': 555,\n",
       " 'probing': 556,\n",
       " 'Nearly': 557,\n",
       " 'bpd': 558,\n",
       " 'however': 559,\n",
       " 'Martinez': 560,\n",
       " 'thrusting': 561,\n",
       " 'Leverkusen': 562,\n",
       " 'fourth-seeded': 563,\n",
       " 'rate': 564,\n",
       " 'Taipei': 565,\n",
       " 'Industry': 566,\n",
       " 'Fax<num>': 567,\n",
       " 'drove': 568,\n",
       " 'Novak': 569,\n",
       " 'accumulated': 570,\n",
       " 'chemical': 571,\n",
       " 'racial': 572,\n",
       " 'Natalya': 573,\n",
       " 'choice': 574,\n",
       " 'privatization': 575,\n",
       " 'atmosphere': 576,\n",
       " 'average': 577,\n",
       " 'purposes': 578,\n",
       " 'Japan': 579,\n",
       " 'send': 580,\n",
       " 'returns': 581,\n",
       " 'CONAKRY': 582,\n",
       " 'alerted': 583,\n",
       " 'goverment': 584,\n",
       " 'Value': 585,\n",
       " 'Kytolehto': 586,\n",
       " 'Dortmund': 587,\n",
       " 'Helens': 588,\n",
       " 'mean': 589,\n",
       " '<num>:17<num>': 590,\n",
       " 'impeachment': 591,\n",
       " 'slid': 592,\n",
       " 'Neuchatel': 593,\n",
       " 'celebrate': 594,\n",
       " 'swings': 595,\n",
       " 'contained': 596,\n",
       " 'Teams': 597,\n",
       " 'pleas': 598,\n",
       " 'chance': 599,\n",
       " 'Oppenheimer': 600,\n",
       " 'taxi': 601,\n",
       " 'then': 602,\n",
       " 'pro-Baghdad': 603,\n",
       " 'Joost': 604,\n",
       " 'Polish': 605,\n",
       " 'market': 606,\n",
       " 'trade': 607,\n",
       " 'manage': 608,\n",
       " 'tabloid': 609,\n",
       " 'Machado': 610,\n",
       " 'organisations': 611,\n",
       " 'shutdown': 612,\n",
       " 'word': 613,\n",
       " 'suspended': 614,\n",
       " 'Journal': 615,\n",
       " 'worrying': 616,\n",
       " 'Finals': 617,\n",
       " 'TALLINN': 618,\n",
       " 'rand': 619,\n",
       " 'communism': 620,\n",
       " 'supply': 621,\n",
       " 'Feugill': 622,\n",
       " 'style': 623,\n",
       " '?': 624,\n",
       " 'Stakes': 625,\n",
       " 'Fernandez': 626,\n",
       " 'Helmut': 627,\n",
       " 'belongs': 628,\n",
       " 'skipper': 629,\n",
       " 'Salah': 630,\n",
       " 'pool': 631,\n",
       " 'permits': 632,\n",
       " 'Wisinga': 633,\n",
       " 'versions': 634,\n",
       " 'ask': 635,\n",
       " 'Banespa': 636,\n",
       " 'guarantee': 637,\n",
       " 'higher': 638,\n",
       " 'Education': 639,\n",
       " 'spread': 640,\n",
       " 'slain': 641,\n",
       " 'accomplice': 642,\n",
       " 'MARINO': 643,\n",
       " 'formally': 644,\n",
       " 'Eletropaulo': 645,\n",
       " 'improved': 646,\n",
       " 'Members': 647,\n",
       " 'Conservation': 648,\n",
       " 'SEA': 649,\n",
       " 'makes': 650,\n",
       " 'stick': 651,\n",
       " 'how': 652,\n",
       " 'Anne': 653,\n",
       " 'whistle-stop': 654,\n",
       " 'surge': 655,\n",
       " 'Legia': 656,\n",
       " 'captivity': 657,\n",
       " 'repairs': 658,\n",
       " 'Comprehensive': 659,\n",
       " 'arson': 660,\n",
       " 'disputes': 661,\n",
       " 'marks': 662,\n",
       " 'strain': 663,\n",
       " 'Meri': 664,\n",
       " 'transferred': 665,\n",
       " 'concert': 666,\n",
       " 'applications': 667,\n",
       " 'scores': 668,\n",
       " 'Sugiyama': 669,\n",
       " 'justified': 670,\n",
       " 'McLaren': 671,\n",
       " 'chamber': 672,\n",
       " 'benchmark': 673,\n",
       " 'plunged': 674,\n",
       " 'elections': 675,\n",
       " 'Bangladesh': 676,\n",
       " 'swap': 677,\n",
       " 'Quarter-finals': 678,\n",
       " 'technical': 679,\n",
       " 'Jiangling': 680,\n",
       " 'bought': 681,\n",
       " 'large': 682,\n",
       " 'exclusive': 683,\n",
       " 'Dariusz': 684,\n",
       " 'importers': 685,\n",
       " 'equal': 686,\n",
       " 'opening': 687,\n",
       " 'C$': 688,\n",
       " 'airlines': 689,\n",
       " 'truck': 690,\n",
       " 'earliest': 691,\n",
       " 'Maronite': 692,\n",
       " 'Heavy': 693,\n",
       " 'Mujtaba': 694,\n",
       " 'controversial': 695,\n",
       " 'turn': 696,\n",
       " 'indicated': 697,\n",
       " 'certain': 698,\n",
       " 'class': 699,\n",
       " 'brothers': 700,\n",
       " 'Widzew': 701,\n",
       " 'Popov': 702,\n",
       " 'peacefully': 703,\n",
       " 'Kurt': 704,\n",
       " 'Lazar': 705,\n",
       " 'seats': 706,\n",
       " 'adequate': 707,\n",
       " 'INDICATORS': 708,\n",
       " 'Fourth': 709,\n",
       " 'PVS': 710,\n",
       " 'trio': 711,\n",
       " 'fair': 712,\n",
       " 'KONG': 713,\n",
       " 'Rubin': 714,\n",
       " 'tales': 715,\n",
       " 'Liberec': 716,\n",
       " 'Two': 717,\n",
       " 'daily': 718,\n",
       " 'BONDS': 719,\n",
       " 'Gaidano': 720,\n",
       " 'Byron': 721,\n",
       " 'contrary': 722,\n",
       " 'combined': 723,\n",
       " 'car': 724,\n",
       " 'War': 725,\n",
       " 'rarely': 726,\n",
       " 'pledged': 727,\n",
       " 'closed': 728,\n",
       " 'dense': 729,\n",
       " 'Lada': 730,\n",
       " 'possibly': 731,\n",
       " 'Batchelor': 732,\n",
       " 'obtain': 733,\n",
       " 'cycling': 734,\n",
       " 'Pitkowski': 735,\n",
       " 'Elena': 736,\n",
       " 'difficulty': 737,\n",
       " 'citizen': 738,\n",
       " 'Takemura': 739,\n",
       " 'tree': 740,\n",
       " 'Higher': 741,\n",
       " 'Finley': 742,\n",
       " 'Karak': 743,\n",
       " 'activist': 744,\n",
       " 'text': 745,\n",
       " 'disagreed': 746,\n",
       " 'ought': 747,\n",
       " 'Carretero': 748,\n",
       " 'Vitesse': 749,\n",
       " 'December': 750,\n",
       " 'Herve': 751,\n",
       " 'Yasushi': 752,\n",
       " 'discuss': 753,\n",
       " 'checking': 754,\n",
       " 'employee': 755,\n",
       " 'Mozambique': 756,\n",
       " 'reason': 757,\n",
       " 'committee': 758,\n",
       " 'VeriSign': 759,\n",
       " 'approaching': 760,\n",
       " 'Barbara': 761,\n",
       " 'want': 762,\n",
       " 'Free': 763,\n",
       " 'resigned': 764,\n",
       " 'suffer': 765,\n",
       " 'Candiotti': 766,\n",
       " 'the': 767,\n",
       " 'Kucera': 768,\n",
       " 'Lead': 769,\n",
       " 'absolute': 770,\n",
       " 'Nagyova': 771,\n",
       " 'shook': 772,\n",
       " 'communities': 773,\n",
       " 'Foindu': 774,\n",
       " 'blacks': 775,\n",
       " 'table': 776,\n",
       " 'married': 777,\n",
       " 'command': 778,\n",
       " 'Petr': 779,\n",
       " 'ambassador': 780,\n",
       " 'Airbus': 781,\n",
       " 'Paola': 782,\n",
       " 'G<num>': 783,\n",
       " 'nothing': 784,\n",
       " 'Phan': 785,\n",
       " 'undertaking': 786,\n",
       " 'God': 787,\n",
       " 'continues': 788,\n",
       " 'S$': 789,\n",
       " 'handling': 790,\n",
       " 'turned': 791,\n",
       " 'photographer': 792,\n",
       " 'state-run': 793,\n",
       " 'suitable': 794,\n",
       " 'Maccabi': 795,\n",
       " 'basketball': 796,\n",
       " 'Roche': 797,\n",
       " 'Colombia': 798,\n",
       " 'John': 799,\n",
       " 'Pedro': 800,\n",
       " 'Liechenstein': 801,\n",
       " 'scrap': 802,\n",
       " 'Faroe': 803,\n",
       " 'intestines': 804,\n",
       " 'Dollar': 805,\n",
       " 'leaves': 806,\n",
       " 'Alpha': 807,\n",
       " 'departure': 808,\n",
       " 'walk': 809,\n",
       " 'line': 810,\n",
       " 'ago': 811,\n",
       " 'grandson': 812,\n",
       " 'requirement': 813,\n",
       " 'punishment': 814,\n",
       " 'platinum': 815,\n",
       " 'moment': 816,\n",
       " 'issues': 817,\n",
       " 'upside': 818,\n",
       " 'Gildea': 819,\n",
       " 'Kathmandu': 820,\n",
       " 'Ogunkoya': 821,\n",
       " 'blanked': 822,\n",
       " 'Carl-Uwe': 823,\n",
       " 'expired': 824,\n",
       " 'chilli': 825,\n",
       " 'masked': 826,\n",
       " 'elimination': 827,\n",
       " 'bln': 828,\n",
       " 'PRIX': 829,\n",
       " 'three-game': 830,\n",
       " 'Wellington': 831,\n",
       " 'second-half': 832,\n",
       " 'Congress': 833,\n",
       " 'doubling': 834,\n",
       " 'premium': 835,\n",
       " 'Slovenian': 836,\n",
       " 'approved': 837,\n",
       " 'scheme': 838,\n",
       " 'Stockholm': 839,\n",
       " 'route': 840,\n",
       " 'EUROPEAN': 841,\n",
       " 'priest': 842,\n",
       " 'speculation': 843,\n",
       " 'superb': 844,\n",
       " 'unexpectedly': 845,\n",
       " 'Zimbabwe': 846,\n",
       " 'Shen': 847,\n",
       " 'filmed': 848,\n",
       " 'luck': 849,\n",
       " 'watched': 850,\n",
       " 'Sales': 851,\n",
       " '*': 852,\n",
       " 'welcomed': 853,\n",
       " 'Prime': 854,\n",
       " 'Stockport': 855,\n",
       " 'mile': 856,\n",
       " 'heartbeat': 857,\n",
       " 'Artur': 858,\n",
       " 'local': 859,\n",
       " 'today': 860,\n",
       " 'Giles': 861,\n",
       " 'Those': 862,\n",
       " 'term': 863,\n",
       " 'hold': 864,\n",
       " 'SIGNS': 865,\n",
       " 'Yasser': 866,\n",
       " 'GAK': 867,\n",
       " 'parents': 868,\n",
       " 'task': 869,\n",
       " 'treatment': 870,\n",
       " 'dictator': 871,\n",
       " 'Nigeria': 872,\n",
       " 'Zealand': 873,\n",
       " 'secondary': 874,\n",
       " 'Christchurch': 875,\n",
       " 'L.': 876,\n",
       " '<num>.': 877,\n",
       " 'autonomy': 878,\n",
       " 'Nyva': 879,\n",
       " 'degree': 880,\n",
       " 'yellow': 881,\n",
       " 'artillery': 882,\n",
       " 'Brno': 883,\n",
       " 'Austria': 884,\n",
       " 'Maybe': 885,\n",
       " 'giant': 886,\n",
       " 'Gilardi': 887,\n",
       " 'Jordi': 888,\n",
       " 'Cristina': 889,\n",
       " '<num>': 890,\n",
       " 'SunGard': 891,\n",
       " 'defeat': 892,\n",
       " 'ATLANTIC': 893,\n",
       " 'kind': 894,\n",
       " 'stations': 895,\n",
       " 'Honda': 896,\n",
       " 'Museeuw': 897,\n",
       " 'Franz': 898,\n",
       " 'guest': 899,\n",
       " 'sessions': 900,\n",
       " 'Tychy': 901,\n",
       " 'FRONT': 902,\n",
       " 'Aronkasei': 903,\n",
       " 'commodity': 904,\n",
       " 'Record': 905,\n",
       " 'Klongprem': 906,\n",
       " 'summit': 907,\n",
       " 'ft': 908,\n",
       " 'yards': 909,\n",
       " 'adopted': 910,\n",
       " 'TOWN': 911,\n",
       " 'ITALIAN': 912,\n",
       " 'Formula': 913,\n",
       " 'Brothers': 914,\n",
       " 'Sierra': 915,\n",
       " 'Mountains': 916,\n",
       " 'intense': 917,\n",
       " 'tentative': 918,\n",
       " 'another': 919,\n",
       " 'Boston': 920,\n",
       " 'Illingworth': 921,\n",
       " 'party': 922,\n",
       " 'discrimination': 923,\n",
       " 'associated': 924,\n",
       " 'sell': 925,\n",
       " 'Gaston': 926,\n",
       " 'OCEI': 927,\n",
       " 'Amtrak': 928,\n",
       " 'Series': 929,\n",
       " 'halted': 930,\n",
       " 'revive': 931,\n",
       " 'LUANDA': 932,\n",
       " 'fix': 933,\n",
       " '<num>-an-hour': 934,\n",
       " 'form': 935,\n",
       " 'Salvation': 936,\n",
       " 'Begum': 937,\n",
       " 'MEXICO': 938,\n",
       " 'Jersey': 939,\n",
       " 'march': 940,\n",
       " 'relationship': 941,\n",
       " 'Petrzalka': 942,\n",
       " 'Staff': 943,\n",
       " 'judicial': 944,\n",
       " 'Rostock': 945,\n",
       " 'recognised': 946,\n",
       " 'Kenya': 947,\n",
       " 'fiscal': 948,\n",
       " 'releases': 949,\n",
       " 'Bahn': 950,\n",
       " 'quoted': 951,\n",
       " 'arable': 952,\n",
       " 'sporting': 953,\n",
       " 'Kurdish': 954,\n",
       " 'Earnings': 955,\n",
       " 'Poland': 956,\n",
       " 'Yates': 957,\n",
       " 'fine': 958,\n",
       " 'Temperatures': 959,\n",
       " 'Kumara': 960,\n",
       " 'pleased': 961,\n",
       " 'CHICAGO': 962,\n",
       " 'Finance': 963,\n",
       " 'Tami': 964,\n",
       " 'ill-fated': 965,\n",
       " 'AUSTRIA': 966,\n",
       " 'doubled': 967,\n",
       " 'Faulding': 968,\n",
       " 'Rovers': 969,\n",
       " 'longitudinal': 970,\n",
       " 'umbrella': 971,\n",
       " 'BRAZILIAN': 972,\n",
       " 'abduction': 973,\n",
       " 'AFTER': 974,\n",
       " 'Transkaryotic': 975,\n",
       " 'y': 976,\n",
       " 'influence': 977,\n",
       " 'None': 978,\n",
       " 'bumped': 979,\n",
       " 'increased': 980,\n",
       " 'predictions': 981,\n",
       " 'strongly': 982,\n",
       " 'Corp': 983,\n",
       " 'v': 984,\n",
       " 'materials': 985,\n",
       " 'Malakwen': 986,\n",
       " 'Andrew': 987,\n",
       " 'slated': 988,\n",
       " 'Tehran': 989,\n",
       " 'AMT': 990,\n",
       " 'tight': 991,\n",
       " 'report': 992,\n",
       " 'filed': 993,\n",
       " 'Dopfer': 994,\n",
       " 'sometimes': 995,\n",
       " 'principal': 996,\n",
       " '<num>TH': 997,\n",
       " 'weakened': 998,\n",
       " 'Olofsson': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Word Map for vocab:\n",
    "word_map = {\"<pad>\":0}\n",
    "for i, word in enumerate(set(train_df[\"word\"])):\n",
    "    word_map[word] = i+1\n",
    "word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "ee2b752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': -1,\n",
       " 'B-PER': 0,\n",
       " 'I-ORG': 1,\n",
       " 'I-PER': 2,\n",
       " 'I-LOC': 3,\n",
       " 'O': 4,\n",
       " 'B-MISC': 5,\n",
       " 'I-MISC': 6,\n",
       " 'B-ORG': 7,\n",
       " 'B-LOC': 8}"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Word Map for ner_tag:\n",
    "ner_map = {\"<pad>\":-1}\n",
    "for i, word in enumerate(set(train_df[\"ner_tag\"])):\n",
    "    ner_map[word] = i\n",
    "ner_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "1a961a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-PER': 0,\n",
       " 'I-ORG': 1,\n",
       " 'I-PER': 2,\n",
       " 'I-LOC': 3,\n",
       " 'O': 4,\n",
       " 'B-MISC': 5,\n",
       " 'I-MISC': 6,\n",
       " 'B-ORG': 7,\n",
       " 'B-LOC': 8}"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_map_without_pad = {}\n",
    "for i, word in enumerate(set(train_df[\"ner_tag\"])):\n",
    "    ner_map_without_pad[word] = i\n",
    "ner_map_without_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2d32ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_train_sent = 0\n",
    "for sentence in train_formatted:\n",
    "    sentence_len = len(sentence[0])\n",
    "    if sentence_len > longest_train_sent:\n",
    "        longest_train_sent = sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "d7724c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_train_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "3582daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map words in sentences to corresponding values:\n",
    "def pad_sentences(sentences_formatted):\n",
    "    train_padded = []\n",
    "    cnt = 0\n",
    "    for sentence in sentences_formatted:\n",
    "        word_lst = sentence[0]\n",
    "        ner_lst = sentence[1]\n",
    "        mapped_word_lst, mapped_ner_lst = [], []\n",
    "        cnt += len(word_lst)\n",
    "        for word in word_lst:\n",
    "            mapped_word_lst.append(word_map[word])\n",
    "        for ner in ner_lst:\n",
    "            mapped_ner_lst.append(ner_map[ner])\n",
    "\n",
    "        word_cnt = len(mapped_word_lst)\n",
    "        diff_ = longest_train_sent - word_cnt\n",
    "        mapped_word_lst = mapped_word_lst + [0] * diff_\n",
    "        mapped_ner_lst = mapped_ner_lst + [-1] * diff_\n",
    "\n",
    "        train_padded.append([mapped_word_lst, mapped_ner_lst])\n",
    "    print(cnt)\n",
    "    return train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "c61e279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204567\n",
      "51578\n"
     ]
    }
   ],
   "source": [
    "train_padded = pad_sentences(train_formatted)\n",
    "dev_padded = pad_sentences(dev_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "9a71dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map words in sentences to corresponding values:\n",
    "def pad_test_sentences(sentences_formatted):\n",
    "    test_padded = []\n",
    "    for sentence in sentences_formatted:\n",
    "        mapped_word_lst = []\n",
    "        for word in sentence:\n",
    "            mapped_word_lst.append(word_map[word])\n",
    "\n",
    "        word_cnt = len(mapped_word_lst)\n",
    "        diff_ = longest_train_sent - word_cnt\n",
    "        mapped_word_lst = mapped_word_lst + [0] * diff_\n",
    "\n",
    "        test_padded.append(mapped_word_lst)\n",
    "    return test_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a2840",
   "metadata": {},
   "source": [
    "### Task 1: Simple Bidirectional LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "671c99af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3465"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "997ef2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14986"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f79c4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "a7baa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        lstm_hidden_dim = 256\n",
    "        lstm_num_layers = 1\n",
    "        linear_output_dim =128\n",
    "        output_dim = 10\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, 100)\n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=256,\n",
    "                          num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear1 = nn.Linear(512, 128)\n",
    "        self.linear2 = nn.Linear(128, 9)\n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #print(inputs.shape)\n",
    "        embeds = self.embeddings(inputs)\n",
    "        #print(embeds.shape)\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(inputs), 1, -1))\n",
    "        lstm_out_dropped = self.dropout(lstm_out)\n",
    "        out = self.linear1(lstm_out_dropped.view(len(inputs), -1))\n",
    "        linear_out_dropped = self.dropout(out)\n",
    "        #l2_out = self.linear2(linear_out_dropped)\n",
    "        elu_out = self.elu(linear_out_dropped)\n",
    "        l2_out = self.linear2(elu_out)\n",
    "        log_probs = F.log_softmax(l2_out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "91fb76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.013137 \tTest Loss: 0.012251\n",
      "Epoch: 2 \tTraining Loss: 0.011642 \tTest Loss: 0.011503\n",
      "Epoch: 3 \tTraining Loss: 0.010595 \tTest Loss: 0.010200\n",
      "Epoch: 4 \tTraining Loss: 0.009587 \tTest Loss: 0.009344\n",
      "Epoch: 5 \tTraining Loss: 0.008823 \tTest Loss: 0.008757\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = train_vocab_size+1 #added <pad> word\n",
    "n_epochs = 5\n",
    "trainloader = torch.utils.data.DataLoader(train_padded, batch_size=64, num_workers=1)\n",
    "devloader = torch.utils.data.DataLoader(dev_padded, batch_size=64, num_workers=1)\n",
    "blstm = BLSTM(VOCAB_SIZE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1, size_average=True) #therefore no need for softmax\n",
    "#criterion = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(blstm.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "test_loss_min = 10000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    blstm.train()\n",
    "    for data, target in trainloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "#         print(data)\n",
    "#         print(target)\n",
    "        #print(torch.cat(data,dim=0).reshape(1,400,316))\n",
    "        #print(torch.cat(data,dim=0).size(0)) I think the problem is here.\n",
    "        output = blstm(torch.cat(data,dim=0))\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, torch.cat(target,dim=0))\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "                # Print statistics\n",
    "        #train_loss += loss.item()*torch.cat(data,dim=0).size(0)\n",
    "        train_loss += loss\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data, target in devloader:\n",
    "            output = blstm(torch.cat(data,dim=0))\n",
    "            loss = criterion(output, torch.cat(target,dim=0))\n",
    "#             test_loss += loss.item()*torch.cat(data,dim=0).size(0)\n",
    "            test_loss += loss\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    test_loss = test_loss/len(devloader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        test_loss\n",
    "        ))\n",
    "    \n",
    "    if test_loss <= test_loss_min:\n",
    "        torch.save(blstm.state_dict(), 'blstm1.pt')\n",
    "        test_loss_min = test_loss\n",
    "\n",
    "  # Process is complete.\n",
    "print('All done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "a2c4d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the test_data:\n",
    "test_df[\"word_formatted\"] = test_df[\"word\"].apply(replace_unk_dev)\n",
    "test_df[\"word_formatted\"] = test_df[\"word_formatted\"].astype(str)\n",
    "\n",
    "test_formatted = format_data_test(test_df)\n",
    "test_padded = pad_test_sentences(test_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "9c20f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm.load_state_dict(torch.load('blstm1.pt'))\n",
    "testloader = torch.utils.data.DataLoader(test_padded[0:100], batch_size=1, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "1f078855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy from trained model:\n",
    "def predict_test(model, dataloader):\n",
    "    prediction_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            output = model(torch.cat(data,dim=0))\n",
    "            _, predicted = torch.max(output.data, 1) \n",
    "            prediction_list.append(predicted)\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "cbb8c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy from trained model:\n",
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            output = model(torch.cat(data,dim=0))\n",
    "            _, predicted = torch.max(output.data, 1) \n",
    "            prediction_list.append(predicted)\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "a4ab20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel_predictions_test(data, pred):\n",
    "    overall_pred = []\n",
    "    for i, sentence in enumerate(data):\n",
    "        non_padded_pred = len(np.nonzero(sentence)[0])\n",
    "        pred_i = pred[i].tolist()[0:non_padded_pred]\n",
    "        overall_pred.append(pred_i)\n",
    "    return overall_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ffc6dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel_predictions(data, pred):\n",
    "    overall_pred = []\n",
    "    for i, sentence in enumerate(data):\n",
    "        actual_sentence = sentence[0]\n",
    "        non_padded_pred = len(np.nonzero(actual_sentence)[0])\n",
    "        pred_i = pred[i].tolist()[0:non_padded_pred]\n",
    "        overall_pred.append(pred_i)\n",
    "    return overall_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "5c3fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions(pred):\n",
    "    overall_pred = []\n",
    "    for sentence in pred:\n",
    "        for idx in sentence:\n",
    "            overall_pred.append(list(ner_map_without_pad.keys())[idx])\n",
    "    return overall_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c4959b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    score = sum(y_true == y_pred)/len(y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "b43e7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on dev:\n",
    "devloader = torch.utils.data.DataLoader(dev_padded, batch_size=1, num_workers=1) #need to do 1 at a time:\n",
    "predictions_dev = predict(blstm, devloader)\n",
    "predictions_dev = unravel_predictions(dev_padded, predictions_dev)\n",
    "predictions_dev = convert_predictions(predictions_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "f8f7f43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-LOC',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-PER',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'I-PER',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-PER',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'I-LOC',\n",
       " 'B-PER',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-PER',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-LOC',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'I-LOC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'I-MISC',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-PER',\n",
       " 'B-MISC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-LOC',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-MISC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-MISC',\n",
       " 'O',\n",
       " ...]"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "384bafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51578\n",
      "51578\n",
      "Dev Accuracy: 0.8618209314048625\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(dev_df[\"ner_tag\"])\n",
    "print(len(y_true))\n",
    "print(len(predictions_dev))\n",
    "print(\"Dev Accuracy:\", accuracy(y_true, predictions_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "52c7b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(name, y_true, y_pred, df):\n",
    "    with open(name, 'w') as f:\n",
    "        for row in df.iloc[0:].iterrows():\n",
    "            f.write(str(row[1][\"index\"]))\n",
    "            f.write(\" \")\n",
    "            f.write(row[1][\"word\"])\n",
    "            f.write(\" \")\n",
    "            f.write(y_true[row[0]])\n",
    "            f.write(\" \")\n",
    "            f.write(y_pred[row[0]])\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "cafd44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(\"dev.out\", y_true, predictions_dev, dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "928db39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test:\n",
    "predictions = predict_test(blstm, testloader)\n",
    "predictions = unravel_predictions_test(test_padded[0:100], predictions)\n",
    "predictions = convert_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "9fb555c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1395"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "0a10d30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['<pad>', 'B-PER', 'I-ORG', 'I-PER', 'I-LOC', 'O', 'B-MISC', 'I-MISC', 'B-ORG', 'B-LOC'])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "3da3311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'B-PER',\n",
       " 'I-ORG',\n",
       " 'I-PER',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'I-MISC',\n",
       " 'B-ORG',\n",
       " 'B-LOC']"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ner_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "7e7aed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_predictions(predictions[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "56d67bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c57df4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 4, 8, 5, 8, 8, 5, 8, 5, 8, 5, 5, 8, 5, 8, 8, 5, 5, 5, 8, 8, 5, 8, 8,\n",
       "         8, 5, 4, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 5, 4, 9, 5, 8, 5, 5, 5, 5, 5, 8, 8, 5, 5, 8, 5, 5, 8, 8, 9,\n",
       "         5, 5, 8, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 8, 5, 8, 5, 5, 5, 8, 5, 8, 4, 8, 5, 5, 8, 5, 5, 5, 8, 5, 8, 5,\n",
       "         8, 8, 6, 8, 8, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 5, 8, 5, 5, 8, 8, 5, 5, 8, 8, 5, 5, 8, 5, 5, 5, 5, 5, 4, 5,\n",
       "         5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 8, 5, 5, 8, 5, 8, 4, 5, 5, 5, 5, 4, 5, 5, 5, 8, 8, 5, 5, 8,\n",
       "         5, 4, 5, 8, 5, 5, 5, 5, 5, 8, 8, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 5, 5, 5, 9, 5, 8, 5, 5, 5, 5, 5, 5, 8, 8, 4, 4, 5, 5, 5, 5,\n",
       "         8, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 6, 5, 5, 8, 4, 8, 6, 5, 5, 8, 5, 8,\n",
       "         5, 8, 5, 8, 5, 5, 5, 5, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 8, 8, 8, 5, 8, 5, 5, 5, 5, 8, 8, 8, 5, 5, 5, 8, 8, 8, 5, 5, 5,\n",
       "         8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([6, 8, 5, 5, 8, 8, 8, 8, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 8, 5, 5, 8, 8,\n",
       "         6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 8, 5, 8, 5, 5, 5, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5,\n",
       "         5, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 8, 5, 8, 5, 5, 8, 8, 5, 8, 8, 5, 5, 8, 5, 5, 8, 8, 5, 6, 5, 5, 5,\n",
       "         8, 5, 5, 8, 5, 8, 8, 8, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 5, 8, 5, 8, 8, 5, 5, 8, 5, 5, 6, 5, 5, 8, 5, 8, 5, 5, 5, 8,\n",
       "         5, 5, 9, 5, 8, 5, 8, 5, 8, 8, 5, 8, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 8, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 8, 8, 5, 8, 5, 4,\n",
       "         5, 5, 8, 8, 0, 5, 8, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 5, 8, 8, 8, 5, 5, 8, 5, 5, 8, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 8, 5, 5, 5, 5, 5, 9, 8, 5, 8, 8, 8, 5, 8, 8, 5, 5, 5, 5, 5, 5,\n",
       "         5, 8, 8, 5, 5, 5, 8, 5, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8,\n",
       "         5, 5, 8, 5, 8, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 4, 5, 6, 5, 8, 5, 5, 5, 5, 5, 5,\n",
       "         8, 5, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 8, 5, 8, 8, 5, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5, 5, 8, 5, 5, 8, 5,\n",
       "         5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 8, 5, 8, 5, 8, 8, 8, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8,\n",
       "         5, 8, 5, 8, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 8, 5, 5, 8, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 8, 5, 5, 5, 8, 5, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 5, 5, 5, 5, 8, 5,\n",
       "         5, 8, 5, 8, 5, 8, 6, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 8, 9, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 8, 5, 8, 5, 8, 8,\n",
       "         8, 8, 5, 8, 5, 5, 5, 5, 5, 5, 8, 8, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 8, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 8, 5, 8, 5, 8,\n",
       "         5, 5, 8, 5, 4, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 5, 5, 5, 8, 5, 5, 8, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 8, 8, 5, 5, 5, 5, 8, 5, 5, 8, 5, 8, 5, 8, 5, 5, 5, 5, 8, 5,\n",
       "         8, 5, 5, 5, 5, 5, 5, 8, 8, 5, 5, 8, 5, 5, 8, 8, 5, 0, 8, 5, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 8, 8, 8, 5, 5, 8, 5, 5, 5, 8, 5, 5, 8, 5, 5, 5, 5, 8, 8, 5, 5,\n",
       "         5, 4, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 8, 5, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 5, 5, 5, 6, 5, 5, 8, 5, 5, 5,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 8,\n",
       "         5, 8, 8, 5, 5, 5, 8, 8, 5, 8, 5, 5, 5, 5, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([6, 8, 5, 8, 5, 5, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([6, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 5, 5, 8, 5, 5, 5, 8, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 8, 5, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 8, 5, 5, 5, 8, 5, 8, 8, 5, 5, 5, 5, 5, 5, 8, 5, 8, 5, 5, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8, 5, 5, 5, 6, 5, 8, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 5, 8, 5, 8, 5, 8, 5, 5, 8, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 8, 6, 8, 5, 5, 8, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5, 5, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 8, 5, 8, 5, 8, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 8, 5, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 8, 5, 5, 5, 8, 5, 8, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 8, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 8, 8, 5, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 6, 5, 8, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5, 8, 5, 5, 5, 5, 8, 5, 5, 5, 8,\n",
       "         8, 4, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 5, 5, 5, 8, 5, 8, 8, 5, 5, 8, 5, 5, 5, 5, 5, 5, 4, 5, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 8, 5, 8, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 5, 8, 5, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 5, 5, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 8, 5, 5, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 8, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([6, 5, 5, 5, 8, 5, 5, 5, 8, 8, 5, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 8, 5, 5, 8, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 4, 5, 5, 5, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 8, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 8, 5, 8, 5, 8, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 8, 8, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 5, 4, 5, 5, 5, 0, 4, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 8, 8, 5, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 8, 5, 5, 8, 6, 5, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 5, 5, 8, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 8, 5, 5, 8, 5, 8, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 5, 8, 5, 8, 8, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 5, 8, 4, 5, 5, 8, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 8, 5, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 8, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 8, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([8, 5, 5, 5, 5, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2bbf1aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb266c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
